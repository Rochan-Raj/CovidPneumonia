{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')\n",
    "from tensorflow import keras\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]\n",
    "# train_path = 'Datasets/train'\n",
    "# valid_path = 'Datasets/test'\n",
    "train_path = 'C:/Datasets/train'\n",
    "valid_path = 'C:/Datasets/test'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob('C:/Datasets/train/*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(vgg.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 25088)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 50178     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,764,866\n",
      "Trainable params: 50,178\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "# create a model object\n",
    "model = Model(inputs=vgg.input, outputs=prediction)\n",
    "# model.layers[1].trainable = True\n",
    "# view the structure of the model\n",
    "model.summary()\n",
    "# print(train_path,valid_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# train_path = 'C:\\Users\\HP\\Downloads\\archive\\chest_xray\\Datasets\\train'\n",
    "# valid_path = 'C:\\Users\\HP\\Downloads\\archive\\chest_xray\\Datasets\\test'\n",
    "train_path = 'C:/Datasets/train'\n",
    "valid_path = 'C:/Datasets/test'\n",
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('C:/Datasets/train',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 10,\n",
    "                                                 class_mode = 'categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('C:/Datasets/test',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 10,\n",
    "                                            class_mode = 'categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp/ipykernel_19556/1525006258.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  r = model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522/522 [==============================] - 625s 1s/step - loss: 0.2100 - accuracy: 0.9289 - val_loss: 0.6761 - val_accuracy: 0.8413\n"
     ]
    }
   ],
   "source": [
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=1,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19556/3767144489.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# plot the accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'train acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'val acc'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')\n",
    "\n",
    "# plot the accuracy\n",
    "plt.plot(r.history['acc'], label='train acc')\n",
    "plt.plot(r.history['val_acc'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('model_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.inception_v3 import InceptionV3"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a9cff5a362bc38ef45d817ae74b1af54d6a076e3d773891282bce078b815ba34"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
